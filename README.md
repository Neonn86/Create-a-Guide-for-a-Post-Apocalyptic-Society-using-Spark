# Using PySpark & Spark SQL to Analyze Climate Change and Restore the Habitats of Future Earth
## Background
<img width="432" alt="image" src="https://user-images.githubusercontent.com/98130185/165662107-662b18e5-aa19-47e9-8bd8-af022f22d6e2.png">

In a remote part of the world, hidden somewhere in Tasmania, researchers of climate change decided to place a steel vault about the size of a school bus. It will operate much like a plane’s black box, and its mission will be to inform whoever discovers it about the end of human civilization. In other words, it will serve as a guide for a post apocalyptic society. It will create an archive for the future habitats of earth that could be critical in forming their society by piecing together the missteps of humanity, should humanity be destroyed by climate change. The box will record leaders’ actions (or inactions) by scraping the internet for keywords relating to climate change from newspapers, social media and peer-reviewed journals. It will collect daily metrics,
including average oceanic and land temperatures, atmospheric carbon dioxide concentration and biodiversity loss.
## Objective
Assume that you are the future species of earth that discovered the Tasmanian box, you need to analyze the data stored in Tasmania to restore the habitats.
## Data Source
- The first dataset contains temperature data by countries. Date starts from 1750 for average land temperature and goes up to 2015. 
- The second dataset contains data on CO2 Emissions per capita across countries from 1960 to 2014.
## Structure
- For which country and during what year, the highest average temperature was observed?
- Analyze the data by country over the years, and name which are the top?
- Merge the two datasets by country, and keep the data from 1960 to 2014.
- What is the correlation between CO2 emissions and temperature change?




